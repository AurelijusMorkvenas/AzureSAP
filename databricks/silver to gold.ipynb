{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6fb8ca3-8037-4272-b757-2f105e9c67ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Single table column transformation (column names)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f234ae9-c017-4169-9fd1-9c578f9141fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List contents of bronze directory to verify our source\n",
    "dbutils.fs.ls('mnt/silver/SalesLT/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe5a94a-4ad4-4432-8dde-b96e347eff2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List contents of silver directory to verify our destination\n",
    "dbutils.fs.ls('mnt/gold/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5927738b-f07f-459a-9e6c-c0ca0df3ddd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read Address table from silver layer as delta format\n",
    "df = spark.read.format('delta').load('/mnt/silver/SalesLT/Address/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3d466ce-0e28-4628-960e-1d30cab91f10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the DataFrame before column name transformation\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7034149-3975-4145-964c-f355f485651e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary PySpark functions for date transformation\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "# Define function to convert column names to snake_case\n",
    "def rename_columns_to_snake_case(df):\n",
    "    \"\"\"\n",
    "    Convert column names from PascalCase or camelCase to snake_case in a PySpark DataFrame.\n",
    "    Example: 'CustomerID' -> 'customer_id', 'firstName' -> 'first_name'\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input DataFrame with columns to be renamed.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with column names converted to snake_case.\n",
    "    \"\"\"\n",
    "    # Get the list of column names from DataFrame\n",
    "    column_names = df.columns\n",
    "\n",
    "    # Dictionary to store mapping of old to new column names\n",
    "    rename_map = {}\n",
    "\n",
    "    for old_col_name in column_names:\n",
    "        # Convert column name using these rules:\n",
    "        # 1. Add underscore before uppercase letters (except first letter)\n",
    "        # 2. Convert all letters to lowercase\n",
    "        # 3. Handle special cases (consecutive uppercase letters)\n",
    "        new_col_name = \"\".join([\n",
    "            \"_\" + char.lower() if (\n",
    "                char.isupper()   # Check if the current character is uppercase\n",
    "                and idx > 0      # Ensure it's not the first character\n",
    "                and not old_col_name[idx - 1].isupper()  # Ensure the previous character is not uppercase\n",
    "            ) else char.lower()  # Convert character to lowercase\n",
    "            for idx, char in enumerate(old_col_name)\n",
    "        ]).lstrip(\"_\")  # Remove any leading underscore\n",
    "\n",
    "        # Avoid renaming to an existing column name\n",
    "        if new_col_name in rename_map.values():\n",
    "            raise ValueError(f\"Duplicate column name found after renaming: '{new_col_name}'\")\n",
    "\n",
    "        # Map the old column name to the new column name\n",
    "        rename_map[old_col_name] = new_col_name\n",
    "\n",
    "    # Rename columns using the mapping\n",
    "    for old_col_name, new_col_name in rename_map.items():\n",
    "        df = df.withColumnRenamed(old_col_name, new_col_name)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a486e27-4ace-4b1e-bb07-ffd608978522",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Apply the transformation to our DataFrame\n",
    "df = rename_columns_to_snake_case(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9568bdfb-1728-4048-a541-1134b2c9ef7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display DataFrame with transformed column names\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64cc644f-ddfc-4cb6-9495-9339cfeebec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**All table columns transformation (column names)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65a0b9b3-28e2-46fc-a37b-d56744944601",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To show the basic format of ls (for debugging/understanding)\n",
    "table_name_temp = []\n",
    "\n",
    "for i in dbutils.fs.ls('mnt/silver/SalesLT'):\n",
    "    table_name_temp.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "041f5fa0-17e4-424d-a169-1cd6122ed12e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f984601-4810-4a90-95e1-13ecaa0adc8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get clean list of table names without path information\n",
    "table_name = []\n",
    "\n",
    "for i in dbutils.fs.ls('mnt/silver/SalesLT'):\n",
    "    table_name.append(i.name.split('/')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f8e274e-c357-4fd4-8997-954ce2b77cd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61d2b6f9-bfbe-4379-90bb-fbd9a187e790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Process each table in silver layer\n",
    "for name in table_name:\n",
    "\n",
    "    # Construct input path from silver layer\n",
    "    path = '/mnt/silver/SalesLT/' + name\n",
    "    print(path)\n",
    "\n",
    "    # Read the table as a DataFrame from silver layer\n",
    "    df = spark.read.format('delta').load(path)\n",
    "    \n",
    "    # Transform column names to snake_case\n",
    "    df = rename_columns_to_snake_case(df)\n",
    "    \n",
    "    # Construct output path in gold layer\n",
    "    output_path = '/mnt/gold/SalesLT/' + name + '/'\n",
    "\n",
    "    # Write transformed DataFrame to gold layer in delta format\n",
    "    df.write.format('delta').mode('overwrite').save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2db63622-da8e-465b-90d7-e2155b967243",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display the final transformed DataFrame (last table processed)\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver to gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
